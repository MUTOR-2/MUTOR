---
###
# unit information: 
# Rhythm
###
title: Rhythm
number: 7
short_description: Unit on Rhythm and Meter
summary: Rhythm is a fundamental element of music around the world. Here we explore the psychological and neural models of rhythm, beat, and meter. Rhythm is defined as the pattern of inter-onset intervals within a train of stimuli. Meter is the repeated, hierarchical characteristic of rhythm, such that repeating streams of stimuli recur at predictable rates. Beat is the perceived accent or emphasis that corresponds to the meter. Prominent models for understanding the perception and production of rhythm include the interval timing model, the covariance model, and the coupled oscillators model. The tuning of different neural populations, or neuronal entrainment, is posed as a likely brain mechanism underlying the perception of beat, rhythm, and meter. We will also discuss higher-level concepts of expressive timing and rubato, and time maps that have beenn derived to visualize these expressive deviations in rhythm and meter.
authors: 
 - Psyche Loui
 - John MacCallum
topics: [Introduction, Perceptual Onset Vs Temporal Envelope, Subdivision, Tactus, Tatum, Accents and Event Stream Vectors, Microtiming and Expressive Timing, Time Maps, Score Time Vs Performance Time, Rhythmogram, Models of Rhythm Perception, Interval Timing ,Covariance Model, CoupledOscillator]
test_questions:
 - What are the important features of sound that enable the perception of rhythmic beats?
 - What is the optimal range of rhythmic function? How do we know?
 - What are the axes of a rhythmogram?
 - What is microtiming?
 - What are the relative advantages and disadvantages of the interval timing model and the coupled oscillator model?

###
# page layout:
# don't change
###
layout: unit
citations: ""
mathjax: true
---

{% include unit_preamble.md %}

# Rhythm

## Introduction

While pitch has received the most attention in perception research, whereas most of music theory consists of putting pitches together to form harmonies, relatively little of common-practice Western musical theory addresses rhythm. Here we define rhythm as the pattern of temporal durations, especially in music. In this unit we will examine the perception and cognition of rhythm. We will begin with the basic observations, e.g. what the optimal range of rhythm and meter are, and how rhythmic subdivisions and expressive timing occur. Then we will discuss the various representations of rhythm, somewhat analogous to visual representations of pitch covered in Unit 5. Finally we will talk about models of rhythm perception and production, and bring in existing literature in an attempt to explain the temporal regularities and deviations that give rise to the human sense of rhythm.

## Perceptual Onset Vs Temporal Envelope
It is important to make a distinction between the temporal envelope, the attack portion of which we usually consider to be the beginning of the sound, and the perceptual onset of a sound. In the case of a percussive sound made by a bell or a piano for example, the attack is nearly instantaneous, while other instruments like violins and clarinets have a variety of attacks at their disposal which can make it difficult pinpoint the onset of their sound. Attacks that last less than 30ms tend to sound percussive, while attacks that are longer than 30ms are more like those of a bowed instrument. In the demo called attack-sync, you will hear two sounds, one with a long attack and one with a short percussive attack. When you start the patch, the two sounds will begin together, although, as you will notice, the one with the longer attack will appear to start later. See if you can adjust the start times such that they appear to start isochronously.

{% include img-figure url="/MUTOR/assets/images/unit7_attack-sync.png" description="Perceptual Onset" %} 

## Subdivision
The optimal range of tempo encoding occurs between 300ms and 1500ms. This is known as the zone of temporal integration, or the tactus. What happens when rhythmic durations are way above tactus? It turns out we subdivide. Subdivision refers to the breaking down of large units into usually even-sized smaller units. In the rhythmic sense the brain is performing chunking, and also building a hierarchical structure of rhythm. As in the frequency dimension for pitch and harmony (see units 5 and 8), small-integer ratios in time play important roles in rhythmic perception. Most rhythmic subdivisions consist of 2:1 ratios, especially in Western music. Rhythms in music of other cultures, e.g. clavé rhythmic patterns in Afro-Cuban and Brazilian rhythms, employ more complex rhythmic patterns, but which can also be broken down into chunks of 2:1 temporal ratios (see Toussaint).

1. it helps working memory by helping chunking

2. clave and bell maps. Toussaint papers - relate somehow.

3. Four dots getting divided into chunks of two - think Gestalt and make pictures.

## Tactus
Using the demo on synchronous clapping, we may observe that when asked to tap in sync to a rhythmic stimulus, people commonly produce isochronous taps at approximately 1-3 Hz (75-200 taps per minute), i.e. with intervals of approximately 300-800ms between each tap. When the musical stimulus to which we are synchronizing contains sound events below this rate, we tend to subdivide the time by tapping twice per sound event. When the sound to which we are synchronizing is above this rate, we tend to subdivide our tapping by tapping once for every two beats. This optimal rate of rhythmic tapping is called the tactus and is in the range of 300-800Hz. The fast end of this range, 300ms or 200 beats per minute, corresponds to the tempo marking of Presto. The slow end, 800ms or 75 beats per minute, corresponds to Adagio. Assuming that our tapping rate reflects our perception of the beat, we can say that the tactus is the optimal range of rhythmic function in music.
Several lines of research have addressed why the tactus seems to operate at this range. Some believe that the tactus aids memory: the tactus may reflect the perceptual system's ability to group distinct sound events together in memory, so that instead of perceiving individual sounds which decay rapidly in sensory memory, we could perceive groups of rhythmic events which hang together to form a Gestalt, or the perception of a whole. Paul Fraisse (from Clarke's chapter, in Deutsch 1999) believed that the tactus arises from the anatomical constraints of the body and motor functions, as our bodies (musculature, nervous systems, etc) prevents us from tapping at rates faster than 3Hz.

## Tatum
In a paper called A Novel Representation for Rhythmic Structure, Vijay Iyer, Jeff Bilmes, Matt Wright, and David Wessel developed a structure for describing rhythmic events called the tatum (a contraction of temporal atom as well as an homage to the great improvising pianist, Art Tatum). A tatum is a data structure that represents the smallest cognitively meaningful subdivision of the main beat and contains information about it's probability of occurence, pitch/timbre, accent, duration, and deviation. Musically speaking, a tatum might correspond to 16th notes or 32nd notes in conventional notation, and a measure of music is represented by a vector of tatums. A high probability of occurence means that the beat is likely to be played (after all, not every beat of a bar is played all the time), the accent determines how loudly the beat will be played (this allows for the beginning of the beat of a conventional meter to be accented, for example), the duration vector could either determine the duration of each beat or represent a range of durations from which a random value is chosen, and the deviation allows for the beats to occur slightly early or late and is meant to model the sort of microtiming that human performers inadvertantely add to their music and that computers lack.

## Accents and Event Stream Vectors
A piece of music is represented by an event-stream vector which contains all of the data for every tatum. An example of a vector representing a bar of 4/4 music might have a set of vectors as represented in table 1.

{% include begin-table description="accents1" %}
| Beat	| Probability	| Accent | Duration	| Deviation |
| 1	| 1	| 1	| 1	| .1 |
| 2	| .5	| .25 |	1	| .1 |
| 3	| 1	| .75 |	1	| .1 |
| 4	| .75	| .5	| 1	| .1 |
{% include end-table %}

Table 1.

In 4/4, the first beat is accented the strongest, the third beat the next strongest, the fourth beat is accented slightly as an upbeat to the next bar, and the second beat is the weakest. This is reflected in the probablity of occurence and accent vectors in table 1. The duration in this case is set at 1 which would signify a full beat and the deviation is very low. Table 2 represents a series of tatums that would produce a waltz-like feel.

{% include begin-table description="accents1" %}
| Beat	| Probability	| Accent | Duration	| Deviation |
| 1 |	1 |	1 |	1	| 0 |
| 2	| .5 |	.25 |	.5	| .1 |
| 3	| .75 |	.75 |	.5	| .1 |
{% include end-table %}

Table 2.

In the above examples, only the main beats of the measures are represented, however, in practice the vectors would contain information about every rhythmic event down to the smallest subdivision.

## Microtiming and Expressive Timing
With respect to rhythm, performances of music are often considered cold and lacking in feeling. It is tempting to think that if the metronome marking is 60 BPM, that the 16th-notes should go by at precisely 250 ms. Human performances, however are filled with small deviations in timing, often called microtiming or expressive timing. These small deviations, while not always overtly noticible, contribute to that human feeling that computer performances lack. In the following two examples, you will hear a melody from Robert Schumann's Traumerei, the first played without expressive timing, while the second includes deviations in timing. 

mechanical timing

<audio controls src="/MUTOR/assets/audios/traumerei_scoretime.mp3"> </audio>

expressive timing

<audio controls src="/MUTOR/assets/audios/Schumann%20-%20Traumerei%20-%20Horowitz.mp3" description="Schumann%20-%20Traumerei%20-%20Horowitz.mp3"> </audio>


(source: Penel & Drake, 2000. Rhythm in music performance and perceived structure. In Desain & Windsor, Ed.)

Above, in the section on the TatuM, along with the parameters of probability of occurence, duration, etc., we also defined a deviation vector. This deviation in timing is meant to mimic the microtiming found in human performance.

## Time Maps

Time maps are visual representations of rhythm and meter. These are useful because they help us visualize, analyze, and understand the black box of each individual performance by each musician. 

Two kinds of time maps we introduce here are the rhythmogram and the maps of performance time as a function of score time. These two time maps are drastically different and are useful in different applications. The rhythmogram is a time map of event frequencies of notes, with enables the inference of the hierarchical rhythmic structure of a musical piece. The maps of score time versus performance time allow for a coherent representation of the entire performance of a piece; they effectively capture the characteristic expressive deviations of each performer. 

In addition to the rhythmogram and the score vs performance time map, various other rhythmic representations deserve mention. Desain and Honing describe a triangular space that represents all possible expressive deviations given a four-note rhythm.

{% include img-figure url="/MUTOR/assets/images/unit7_desainhoning.png" description="DesainHoning" %} 
(image source: Desain & Honing, 2003. Perception.)

Other statistical methods to analyze rhythm and expressive microtiming are also widely used. Benadon uses histograms, which are graphs plotting the occurrence frequencies of events, to diagram the beat-upbeat ratios (BURs) of the swing rhythm in jazz.

## Score Time Vs Performance Time
Given the discussion of microtiming above, it should be clear by now that there is not necessarily a 1:1 correlation between the printed score and what a performer plays. A simple score may only contain pitches, rhythms, some dynamics, and information about the tempo and meter. Although it may lack direction about how to vary the timing expressively, we are not necessarily meant to interpret that lack of direction as an indication that we should play the music as straight and precisely as possible. When directions are given, they are often vague at best, as in the term rubato. As we mentioned above, a computer simulation that lacks microtiming and is based only on what we might call score time tends to feel cold and mechanical. We can begin to understand what a performer brings to the piece with respect to expressive timing by plotting the score time against the performance time as in figure 1.

score time vs. performance time

{% include img-figure url="/MUTOR/assets/images/unit7_score_v_performance.png" description="Score time vs performance time" %}
Figure 1. Score time versus performance time.

By modelling the relationship between score and performance time, one can create a synthesizer that will play music with a more human feel (A Novel Representation for Rhythmic Structure).

## Rhythmogram
The rhythmogram is an effective way to visualize rhythmic structure in a musical score or performance. First used by Neil Todd 
(mentioned in E. Clarke in Deutsch, 1999), the rhythmogram is a graph of musical performances with time on the x axis and a low-frequency filterbank on the y axis.

To visualize the low-frequency filterbank, consider a set of very low-frequency bandpass filters arranged logarithmically. For instance, several filters along the filterbank could be: 0.125Hz, 0.25Hz, 0.5Hz, 1Hz, 2Hz, and 4Hz. The rhythmogram plots musical time on the x axis and these filters on the y axis.

{% include img-figure url="/MUTOR/assets/images/unit7_rhythmogram1.gif" description="Rhythmogram1" %}

The axes of the rhythmogram: frequency filterbank vs. time.

In this representation, notes which occur quickly, e.g. sixteenth notes, would show activity at the highest frequency filters along the filterbank.

{% include img-figure url="/MUTOR/assets/images/unit7_rhythmogram2.gif" description="Rhythmogram2" %}
Fast notes activate high-frequency filters along the filterbank.

Notes occurring at the next fastest level, i.e. eighth notes, would appear as activity at the next level of filters:
 
{% include img-figure url="/MUTOR/assets/images/unit7_rhythmogram3.gif" description="rhythmogram3" %}
The next level of notes (quarter notes) would then appear energy at 1Hz filters, half notes at 0.5Hz filters, and finally, at the highest level, whole notes would appear at 0.25Hz filters. 

{% include img-figure url="/MUTOR/assets/images/unit7_rhythmogram4.gif" description="rhythmogram4" %}
Taken together, we see an emergent tree-like diagram of rhythmic activity, with the different layers of the filterbank representing each level of rhythmic structure and importance. Thus, we can say that the rhythmogram provides a visual representation of the tree-like rhythmic structure of a musical piece.

{% include img-figure url="/MUTOR/assets/images/unit7_rhythmogram5.gif" description="rhythmogram5" %}
The theoretically derived rhythmogram can be applied to actual performances to represent not only the rhythmic structure of the composition, but also the perceptual experience of the piece as a function of its decay rate over time. This links the mathematical idea of a filterbank to the auditory system, with its built-in mechanisms for the detection of onsets. In addition, the rhythmogram could be used to represent the sound structure of speech as well as music.

An application of the rhythmogram to represent perceptual decay is shown here in the speech utterance "tennessee air":

{% include img-figure url="/MUTOR/assets/images/unit7_tenessee_rhythmogram.png" description="tenessee_rhythmogram.png" %}

(image source: http://www.dcs.shef.ac.uk/~guy/pdf/icslp94.pdf) 

Instead of a low-frequency filterbank, the above rhythmogram uses a the rate of decay of memory as its y axis. Notes which are more important in the rhythmic structure would be in memory for longer; thus, it would take a higher number of seconds to decay from memory. 

This use of the rhythmogram also yields a tree-like structure, which can be represented diagramatically:
 
{% include img-figure url="/MUTOR/assets/images/unit7_tenessee_hierarchy.png" description="tenessee_hierarchy.png" %}

(image source: http://www.dcs.shef.ac.uk/~guy/pdf/icslp94.pdf) 

Using the rhythmogram, the hierarchical structure of music and speech can be derived based on signal processing methods.

## Models of Rhythm Perception
Humans seem to have remarkable ability to perceive and produce rhythm. How do we account for such abilities scientifically? What is it about our bodies and our minds that enables the perception and production of rhythm? 

Here we present two models of rhythm perception and production: the interval timing model and the coupled oscillator model. The interval timing model predicts the inter-onset interval between two events by viewing 
Again, it is not clear that the answer must be one or the other; the truth may well lie somewhere in between, or it may be a third model which differs from both interval timing and coupled oscillator models. 

An alternate model that relates rhythmic perception and production uses the Bayesian prediction framework, which predicts the probability of an event based on its prior probability, via the BayesRule. This framework has been applied to rhythm to predict rhythm production based on rhythm perception (Sadakata & Desain, 2006). 

## Interval Timing
Interval timing models of rhythmic perception and production posit that each rhythmic event is related to its previous event via a pacemaker, or accumulator. The pacemaker is a central timekeeper that sets an overall speed, or tempo, controlling the series of rhythmic events. The accumulator receives pulses from the pacemaker, and compares each interval to the interval immediately before it. 

Pacemaker and accumulator models are well supported by neural evidence. Neurological patients with lesions in the basal ganglia, such as patients with Parkinson's Disease, have trouble keeping time accurately at high levels; that is, they tend to speed up or slow down their tempo significantly over time. In contrast, patients with cerebellar damage have trouble maintaining time at smaller intervals; their timing tends to be uneven and noisy. Taken together, these results suggest that the basal ganglia may act as a pacemaker, or a central timekeeper, whereas the cerebellum acts as an accumulator which corrects each individual rhythmic event by comparing it to its previous event.

## Covariance Model
One common observation in rhythm production is that when asked to tap evenly, humans tend to produce rhythms that are slightly uneven. For example, suppose you are required to produce even taps of two taps per second. Here is a time line of your expected taps, in seconds:
 
{% include img-figure url="/MUTOR/assets/images/unit7_eventap.gif" description="eventap.gif" %}

However, it turns out that the actual measured production is as followed:

{% include img-figure url="/MUTOR/assets/images/unit7_eventap2.gif" description="eventap2.gif" %}

The simplest mathematical model to predict this pattern of behavior is the covariance model. The covariance model proposes that a negative correlation exists between the time interval between two taps and the time interval between the two taps immediately preceding. That is, if tn is the time interval between successive taps, i.e.

{% include img-figure url="/MUTOR/assets/images/unit7_eventap3.gif" description="eventap3.gif" %}

Then for every time interval tn, the next time interval, tn+1, is negatively correlated in length.

{% include img-figure url="/MUTOR/assets/images/unit7_eventap4.gif" description="eventap4.gif" %}

 If tn is long, then tn+1 is short; if tn is short, then tn+1 is long. (This is the negative correlation principle). 
Much of the deviations between rhythmic tapping can be modelled this way.

## Coupled Oscillator
In contrast to the IntervalTiming models of rhythm, the coupled oscillator models conceive of rhythm as the result of recurring cycles of individual processes known as oscillators. An oscillator is a device which produces a recurrent output at a fixed frequency determined by its own properties, with an amplitude that depends on the amount of energy given to it. A sine wave is a simple output of an oscillator. A spring and a pendulum are both prime examples oscillators. 

{% include img-figure url="/MUTOR/assets/images/unit7_grandclock1.gif" description="grandclock1.gif" %}

A grandfather clock contains a pendulum, which is a kind of oscillator.

{% include img-figure url="/MUTOR/assets/images/unit7_pendulum2.gif" description="pendulum2.gif" %}

A simple pendulum. (image source: http://webpages.ursinus.edu/mtakats/gifcat/pendulum.html)

{% include img-figure url="/MUTOR/assets/images/unit7_spring.gif" description="spring.gif" %}

A spring is another example of a simple oscillator. (image source: http://webpages.ursinus.edu/mtakats/gifcat/spring.html)

The coupled oscillator model states that a set of oscillators entrain to each other - that is, their frequencies become tuned to each other, or become coupled as a result of the interaction between two oscillators.

{% include img-figure url="/MUTOR/assets/images/unit7_springsym.gif" description="springsym.gif" %}

Coupled oscillators as two symmetrical springs. (image source: http://webpages.ursinus.edu/mtakats/gifcat/springsym.html)

Coupled pendulum oscillators (image source: http://xeon.concord.org:8080/modeler/index.html)

{% include img-figure url="/MUTOR/assets/images/unit7_pendulum.gif" description="pendulum.gif" %}
{% include img-figure url="/MUTOR/assets/images/unit7_pendulum.gif" description="pendulum.gif" %}
<!-- Can you make the two pendulum images right next to each other? (left and right, not up and down) -->

Applied to rhythm, the coupled oscillator model states that rhythm is the result of a set of internal oscillators which entrain towards the expected rhythm. Large and Kolen (1994) and McAuley (1996) have modeled the perception and production of rhythm using coupled oscillators, where the placement of each beat within a metric structure is set by the phase of the oscillator, and individual oscillators entrain towards the recurrent beat. The use of coupled oscillators has led to some successful beat-finding algorithms. Coupled oscillator theories are computationally attractive as they can predict many observations, including the perception of meter as a recurrent rhythmic pattern, using relatively elegant mathematical models. Unfortunately, we are not yet sure of physiological bases of coupled oscillator models.

# A Mathematical Model of Meter: Clarence Barlow's Indispensability Function

In Western music, the inherent quality of a meter can be, within limits, encoded by the time signature and the beams employed in its notation. While measures in 3/4, 6/8 and 12/16 meters contain the same number of 16th notes, musicians have learned accentuate the pulses in order to give the meter a clear contour. A meter can be considered a kind of _relief_ upon which the gestalt of a rhythm is based. While a meter conditions a rhythm, it can also go against the grain of the former by forming _syncopations_. A rhythm in conjunction with a series of pitches forms the gestalt of a melody.
The composer and music theorist Barlow developed in the 1970s a quantitative model which is capable of yielding a _metric profile_ for a given meter which assigns a unique weight value (indispensability) to each of its pulses. The term indispensability stems from _thinning_ experiments in which Barlow asked subjects to determine which pulses are necessary to maintain a sense of a meter when successively turning its pulses into rests and therefore are less **dispensible**. A metric profile thus represents a kind of "natural order" akin to a harmonic series, but just with the tones derived from the harmonic series, composers and improvising musicians are free decide when and how to violate this order, thus playing with the sense of tension and relief.

A meter consists of one to several _strata_ highlighting its hierarchical nature. For example,  6/8 meter is composed of two strata, one with 2 pulses (dotted quarter notes) at the highest level and another with 3 pulses (eighth notes subdividing the dotted quarter notes) at the next lower level.

Each stratum is identified by a _prime divisor_. These are "basic" meters, usually with 2 and 3 pulses; but additive meters such as 5 (2+3) or 7 (2+2+3), can also be defined as basic meters. The indispensability values of a 2 meter are 1 0, those of a 3 meter are 2 0 1, and those of a 5 (2+3) meter are 4 0 3 1 2.

The following meters have the same number of pulses, but a different stratification yielding the following profiles:<br/>
`3/4 (3x2x2):   11 0 6 3 9 1 7 4 10 2 8 5`<br/>
`6/8 (2x3x2):   11 0 6 2 8 4 10 1 7 3 9 5` <br/>
`12/16 (2x2x3): 11 0 4 8 2 6 10 1 5 9 3 7`<br/>

<br/>
{% include img-figure url="/MUTOR/assets/images/unit7_indispensibility2.png" description="Metric profiles for different meters with 12 pulses each" %}

The values for the first and second levels are also contained herein: to make these evident, subtract the difference between the quantity of pulses at the level shown above and those at the desired level from the indispensability, keeping only non-negative numbers, e.g. for 3/4 (the number of pulses on the 3rd level as shown above is 12):<br>
1st level (pulse quantity 3:subtract 12-3,i.e.9):<br/>
`2 - - - 0 - - - 1 - - -` <br/>
2nd level (pulse quantity 6:subtract 12-6,i.e.6):<br/> 
`5 - 0 - 3 - 1 - 4 - 2 -` <br/>

Note that at all levels, the indispensability of the first pulse is always one less than the number of pulses, and that that of the second pulse is always zero.

The metric profile of a compound meter is obtained by adding the indispensability values of the basic meter of each strata, rotating the first value backwards in each case. In the following examples the dashes are replaced by the repeating the preceding number.

12/16 meter:<br/>
`Pulse #     2  3  4  5  6  7  8  9  10 11 12 1`<br/>   
`1st stratum 0  0  0  0  0  0  1  1  1  1  1  1`<br/>
`2nd stratum 0  0  0  1  1  1  0  0  0  1  1  1`<br/>
`3rd stratum 0  1  2  0  1  2  0  1  2  0  1  2`<br/>

`Pulse # 2  3  4  5  6  7  8  9  10 11 12 1`<br/>
`*1:     0  0  0  0  0  0  1  1  1  1  1  1`<br/>
`*2:     0  0  0  2  2  2  0  0  0  2  2  2`<br/>
`*2*2:   0  4  8  0  4  8  0  4  8  0  4  8`<br/>
`Sum     0  4  8  2  6  10 1  5  9  3  7  11`<br/>
<br/>
Rotating the first pulse back to the beginning yields:<br/>
`11  0  4  8  2  6  10  1  5  9  3  7`<br/>

Similarly, for a 2x3x5 meter (e.g. a 6/4 meter with every quarter note further divided by 5 sixteenth note quintuplet), we initially get:<br/>
`Pulse #     2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 1` <br/>
`1st stratum 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1` <br/>
`2nd stratum 0  0  0  0  0  1  1  1  1  1  2  2  2  2  2  0  0  0  0  0  1  1  1  1  1  2  2  2  2  2` <br/>
`3rd stratum 0  3  1  2  4  0  3  1  2  4  0  3  1  2  4  0  3  1  2  4  0  3  1  2  4  0  3  1  2  4` <br/>
<br/>
Now we multiply each stratum by the product of the pulse counts of the preceding strata (1 for the first stratum) and add the values together:<br/>
<br/>
`Pulse #  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  1` <br/>
`*1:      0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1` <br/>
`*2:      0  0  0  0  0  2  2  2  2  2  4  4  4  4  4  0  0  0  0  0  2  2  2  2  2  4  4  4  4  4` <br/>
`*2*3:    0 18  6 12 24  0 18  6 12 24  0 18  6 12 24  0 18  6 12 24  0 18  6 12 24  0 18  6 12 24` <br/>
`Sum      0 18  6 12 24  2 20  8 14 26  4 22 10 16 28  1 19  7 13 25  3 21  9 15 27  5 25 11 17 29` <br/>
<br/>
Rotating the final number back to the beginning yields:<br/>
`29  0 18 6  12 24  2 20  8 14 26  4 22 10 16 28  1 19  7 13 25  3 21  9 15 27  5 25 11 17` <br/>
<br/>
This process is formalized by the following formula of Clarence Barlow (the rotation is given by the addition of the 1 within the round brackets as well as the square brackets):

Formula of the indispensability Ψ of the nth pulse of a meter of stratification p1 x p2 x p3 x...x pz<br/>

{% include img-figure url="/MUTOR/assets/images/unit7_indispensibility.png" description="Barlow's indispensibility formula" %}
<br/>
whereby <br/>
p0 = pz+1 = 1<br/>
n = position in the bar of the pulse in question, starting at 1<br/>
pj = stratification divisor on level j<br/>
z = number of levels in the stratification <br/>
Ψp(x) = indispensability of the xth pulse of a first-order bar with the prime stratification p<br/>
\[x\] = whole-number component of x (floor)<br/>

The indispensability of the 24th pulse (n=24; z=3) can thus be calculated:<br/>
For r=0: (2 * 3) * Ψ5(1 + [1 + (22 mod 30 / 1)] mod 5) = 6 * Ψ5(1 + 23 mod 5) = 6 * Ψ5(1 + 3) = 6 * 1 = 6 <br/>
For r=1: 2 * Ψ3(1 + [1 + (22 mod 30 / 5)] mod 3) = 2 * Ψ3(1 + 5.4 mod 3) = 2 * Ψ3(1 + 2) = 2 * 1 = 2 <br/>
For r=2: 1 * Ψ2(1 + [1 + (22 mod 30 / 15)] mod 2) = 1 * Ψ2(1 + 2.47 mod 2) = 1 * Ψ2(1 + 0) = 1 * 1 = 1 <br/>
<br/>
The sum of the three members is therefore 9 (see above).<br/>

Barlow has often used such profiles in his compositions based on a generative probabilitic approach (i.e. weighted chance), his 30-minutes piano piece Çoǧluotobüsişletmesi among them.

# Summary
We have provided an overview of the physic and biology of rhythm perception and production. Our perception of rhythm depends on sounds; in particular on perceptual accents or event onsets within the streams of sounds to which we are exposed in the environment. Rhythm seems to function optimally at the range of the Tactus, and can be subdivided into the smallest unit known as the Tatum. Microtiming and expressive timing can be described using time maps, which include the rhythmogram and graphs relating score time to performance time. Models of rhythm and meter can be divided into two broad classes known as the interval timing models and the coupled oscillator models. In some cases, rhythm production can also be modeled as covariance. The Bayesian method provides a method to relate rhythm perception with production.

# References

Vijay Iyer's thesis: http://cnmat.berkeley.edu/People/Vijay/00.3%20Table%20of%20Contents.html#anchor292689

Desain & Windsor (2000) book on rhythm perception and production: http://www.nici.kun.nl/mmm/papers/rpp-book/rpp-book.html

Todd, N.P. The auditory ‘primal sketch’: A multiscale model of rhythmic grouping. Journal of New Music Research, vol. 23, pp. 25-70, 1994.

Benadon, Fernando. 2006. Slicing the beat : Jazz eighth-notes as expressive microrhythm. Ethnomusicology, 50(1), 73-98.

Desain & Honing, Perception. 2003.

Diedrichsen, Ivry & Pressing. 2003. Cerebellar and basal ganglia contributions to interval timing. http://ist-socrates.berkeley.edu/~ivrylab/pdf/dip_03.pdf

Sadakata, M., Desain, P.W.M., & Honing, H.J. (2006). The Bayesian way to relate rhythm perception and production. Music Perception, 23 (3), 267-286.

Buhusi & Meck. (2005). Nature Neuroscience 
http://www.nature.com/nrn/journal/v6/n10/pdf/nrn1764.pdf

Large & Kohlen. (1994). Connection Science, 6 (1), 177 - 208.

## Links and Downloads

AccelerandoExplorer <!-- we used to have a Max patch for this Accelerando Explorer; does either of you still have it? PL -->

Doug Eck's java simulator of oscillators - provides explanations of coupled oscillator models in rhythm. http://www.iro.umontreal.ca/~eckdoug/vibe/index.html 

Java applet demo of coupled oscillators: http://www.lon-capa.org/~mmp/applist/coupled/osc2.htm 

Peter Desain's Music, Mind, and Machine Group offers several downloadable demos on expressive timing and the Bayesian model of rhythm. http://www.nici.kun.nl/mmm/
 
{% include unit_postamble.md %}
