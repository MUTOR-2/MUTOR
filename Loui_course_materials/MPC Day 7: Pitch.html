<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 7.14 (458244)"/><meta name="keywords" content="notes"/><meta name="altitude" content="53"/><meta name="created" content="2014-02-12 05:02:23 +0000"/><meta name="latitude" content="41.76707547161892"/><meta name="longitude" content="-72.75591161108832"/><meta name="source" content="mobile.iphone"/><meta name="updated" content="2019-12-10 14:08:37 +0000"/><title>MPC Day 7: Pitch</title></head><body><div>Project Proposal due tonight</div><div><span style="font-weight: bold;">Pitch</span></div><div><a href="MPC%20Day%207%3A%20Pitch.html.resources/07-harmonic-waves.maxpat">07-harmonic-waves.maxpat</a></div><div>Virtual pitch demo</div><div><a href="MPC%20Day%207%3A%20Pitch.html.resources/a_ascending.wav">a_ascending.wav</a></div><div>Missing fundamental </div><div>     Theories of pitch perception</div><div>          Place theories (spectral models)</div><div>               harmonic template matching model</div><div>          Time theories (temporal models) </div><div>               autocorrelation model </div><div>Pitch class circle</div><div>Probe tone ratings </div><div>Multidimensional scaling</div><div>Pitch chroma</div><div>Pitch height</div><div>Shepard tone<a href="MPC%20Day%207%3A%20Pitch.html.resources/Shepard%20tone%20illusion.maxpat">Shepard tone illusion.maxpat</a><a href="MPC%20Day%207%3A%20Pitch.html.resources/shepard.help">shepard.help</a><a href="MPC%20Day%207%3A%20Pitch.html.resources/ShepardZoomDemo.m">ShepardZoomDemo.m</a></div><div>Tonal space</div><div><br/></div><div>2 presentations on pitch and pitch space - from 10:50 - 11:30?</div><div>If time: experiments/Russo Functional Hearing Test for Musicians</div><div><br/></div><div>TableOfContents</div><div><ol><li><div>Unit5Introduction</div></li><li><div>FrequencyAndPitch</div></li><li><div>FundamentalFrequency</div></li><li><div>VirtualPitch</div></li><li><div>Synthetic vs. Analytic pitch perception</div></li><li><div>PitchPerceptionModels</div></li><li><div>ExistenceRegion for pitch</div></li><li><div>Pitch as a FormBearingMedium</div></li><ol><li><div>AbsolutePitch</div></li></ol><li><div>PitchAndHarmony</div></li><ol><li><div>Pitches, Scales, and TuningSystems</div></li></ol><li><div>PitchSpaces</div></li></ol><ol><li><div>SumMary</div></li><li><div>ReferenceS</div></li><li><div>LinksnDownloads</div></li><li><div>QuizItems</div></li></ol></div><div>Unit5Introduction</div><div>Pitch is one of the most important attributes of music. This unit will cover the different types of pitch we may perceive in music. We start with the relationship between frequency in the physical world and pitch in the perceptual world. We continue to discuss the cases when pitch may occur in the absence of energy at the perceived frequency, and propose models which may account for this perceptual phenomenon. Different types of pitch perception will be discussed, includng the qualities that makes it form transposable melodies and harmonies. Finally, we will discuss pitch spaces and tuning systems that enable the systematic use of pitch as a musical medium.</div><div><br/></div><div>FrequencyAndPitch</div><div>The concept of sound frequencies was first introduced in Unit 1. While frequency is a <span style="font-style: italic;">physical</span> attribute which characterizes waves of sound energy, pitch is a <span style="font-style: italic;">perceptual</span> attribute which describes our experience of tones. Generally, the higher the frequency of a sound, the higher the perceived pitch.</div><div>Pitch is perceived in sounds that are periodic; i.e. sounds with features which recur at regular frequencies. Aperiodic sounds are more likely to be perceived not as pitches, but as noise or transient (quickly-changing) clicks. Thus, pitch perception depends on frequencies of sounds entering the ears.</div><div>The orchestra tunes to the pitch of concert A4, which usually corresponds to sounds with the fundamental frequency of 440Hz. This means that while energy of sound waves may be at 440Hz or above, we perceive sounds to be equivalent in pitch as a pure tone at 440Hz.</div><div><a href="MPC%20Day%207%3A%20Pitch.html.resources/does-phase-matter.mxb">does-phase-matter.mxb</a><a href="MPC%20Day%207%3A%20Pitch.html.resources/pure-tone-demo.mxb">pure-tone-demo.mxb</a></div><div>Our percept of pitch is <span style="font-weight: bold;">logarithmically organized</span> such that an octave above concert A is twice its frequency, therefore, 880Hz; whereas the next octave above 880Hz is twice 880Hz, which is 1760Hz. Thus each octave corresponds to a doubling in frequency, resulting in a logarithmic function relating frequency to pitch.<a href="MPC%20Day%207%3A%20Pitch.html.resources/sensory-dissonance-function.mxb">sensory-dissonance-function.mxb</a></div><div><img src="MPC%20Day%207%3A%20Pitch.html.resources/20A026FD-6EB4-4C7C-917F-11D6E0F43F5B.jpg" height="440" width="527"/><a href="MPC%20Day%207%3A%20Pitch.html.resources/virtual_pitch_demo.maxpat">virtual_pitch_demo.maxpat</a></div><div>(image source: Campbell, M. and Greated, C. (1987). The Musician's Guide to Acoustics. New York: Shirmer Books.)</div><div><br/></div><div>FundamentalFrequency</div><div>The percept of pitch generally correlates with the <span style="font-weight: bold;">fundamental frequency</span> of sound waves. The fundamental frequency is defined as the highest common factor of all sound waves from the same source, which gives rise to the pitch percept.</div><div><br/></div><div>As an illustration of fundamental frequency and its relationship with pitch, consider four tones, each with different numbers of components, but where all the components are integer multiples of 440Hz. The perceived pitch of these four tones should be the same, although the frequencies which comprise them are different. The higher components in frequencies of n times 440Hz do not change the perceived pitch, but they do influence the percept of timbre.</div><div>The following are four tones with differing numbers of partials, but with the same fundamental frequency and thus the same perceived pitch.</div><div>Pure tone at 440Hz <img src="MPC%20Day%207%3A%20Pitch.html.resources/E8355A13-00A6-4767-A191-07A357F5D45B.png" height="88" width="280"/><br/></div><div>Two-tone complex with fundamental frequency of 440Hz <img src="MPC%20Day%207%3A%20Pitch.html.resources/B1F6C0E3-1FA8-4021-B904-D908180E1C5F.png" height="80" width="280"/><br/></div><div>Three-tone complex with F0 of 440Hz <img src="MPC%20Day%207%3A%20Pitch.html.resources/677B65C3-AAAE-4AE2-A29F-0C9B17DE580A.png" height="88" width="280"/><br/></div><div>Four-tone complex with fundamental frequency of 440Hz <img src="MPC%20Day%207%3A%20Pitch.html.resources/114399BD-4E3D-41C5-987F-4B5FFD64028E.png" height="88" width="280"/><br/></div><div>Three-tone complex with <span style="font-weight: bold;">missing fundamental</span> of 440Hz <img src="MPC%20Day%207%3A%20Pitch.html.resources/83548300-C8D1-4D3B-897C-CAA9527B0E44.png" height="89" width="272"/><br/></div><div>The fundamental frequency of a sound is also known as its periodicity pitch, and is shorthanded as F0.</div><div>VirtualPitch</div><div>Sometimes, pitch is perceived at a fundamental frequency even when energy is nonexistent at the frequency of the fundamental. This is known as virtual pitch. Virtual pitch, also known as the missing fundamental, is a classic phenomenon in audition where sound is perceived at a frequency where no energy is present. When energy from harmonic components other than the fundamental is present at integer multiples of the fundamental frequency, the brain is able to infer a virtual pitch at the missing fundamental. Mechanisms that the brain may be using to infer virtual pitch is still an issue of debate, although various models of pitch perception have been proposed to explain this perceptual phenomenon.</div><div>Virtual pitch is only perceived if the missing fundamental frequency lies within the existence region for pitch, which is approximately the frequency range of 30Hz to 3.2 kHz (Pressnitzer et al, 2001).</div><div>Virtual pitch audio demonstrations (from ASA demonstration CD):</div><div>Spectral and virtual pitch: you will hear a tune of Westminster chimes presented in virtual pitch, due to the configuration of spectral components harmonically related to the missing fundamental. The spectral and virtual pitches will each be masked in the second and third clips.</div><div><a title="External link to http://cnmat.berkeley.edu/Music108/mp3s/asacd/40%20Masking%20Spectral%20And%20Virtual%20Pitc.mp3" href="http://cnmat.berkeley.edu/Music108/mp3s/asacd/40%20Masking%20Spectral%20And%20Virtual%20Pitc.mp3">1</a> <a title="External link to http://cnmat.berkeley.edu/Music108/mp3s/asacd/41%20Masking%20Spectral%20And%20Virtual%20Pitc.mp3" href="http://cnmat.berkeley.edu/Music108/mp3s/asacd/41%20Masking%20Spectral%20And%20Virtual%20Pitc.mp3">2</a> <a title="External link to http://cnmat.berkeley.edu/Music108/mp3s/asacd/42%20Masking%20Spectral%20And%20Virtual%20Pitc.mp3" href="http://cnmat.berkeley.edu/Music108/mp3s/asacd/42%20Masking%20Spectral%20And%20Virtual%20Pitc.mp3">3</a></div><div><br/></div><div>Synthetic vs. Analytic pitch perception</div><div>Having made the distinctions between fundamental frequency, frequency components, and pitch, one question that arises concerns the hearing of partials versus the fundamental pitch of a complex sound. When do we hear a complex of partials as a chord, and when do we hear it as unified sound? What determines whether we synthesize sound components into a unified percept, or analyze sounds into their components?</div><div><br/></div><div>The distinction between <span style="font-weight: bold;">synthetic</span> and <span style="font-weight: bold;">analytic</span> pitch perception - i.e. taking sounds apart into its frequency component vs. combining them - seems to depend somewhat on the <span style="font-weight: bold;">comodulation</span> of the partials. When a sound contains frequency components that modulate together, they are more likely to be heard as a whole. One example of comodulated partials is in speech, where frequency components tend to be highly correlated. Thus speech sounds are usually heard as unified percepts rather than individual components.</div><div>There is also some evidence for individual differences in synthetic versus analytic pitch perception. Evidence shows that left-handed listeners are more likely to hear frequency components whereas right-handed listeners are more likely to listen synthetically (Laguitton, Demany, et al, 1998). This may have to do with differential hemispheric asymmetries in the Heschl's gyrus of the auditory cortex (Schneider et al, 2005).</div><div>One effective assessment of synthetic versus analytic pitch perception depends on use of virtual pitch. In the demo <a title="External link to http://cnmat.berkeley.edu/Music108/mp3s/asacd/48%20Analytic%20Vs%20Synthetic%20Pitch.mp3" href="http://cnmat.berkeley.edu/Music108/mp3s/asacd/48%20Analytic%20Vs%20Synthetic%20Pitch.mp3">here</a>, you will hear two harmonic complexes with frequencies of 800 and 1000Hz, followed by 750 and 1000Hz. The first complex implies a missing fundamental of 200Hz, whereas the second implies a 250Hz virtual pitch. Try judging whether you hear the tones go up or down; if you hear them going down you are a <span style="font-weight: bold;">analytic pitch listener</span>, whereas if you hear an ascending interval you are a <span style="font-weight: bold;">virtual pitch listener</span>.</div><div><br/></div><div>PitchPerceptionModels</div><div>For centuries, hearing and musical scientists have attempted to build an optimal model that would account for pitch perception. An accurate model of pitch perception must describe how components of frequencies are converted into pitch in the logarithmic scale; it must also explain how fundamental frequencies are calculated, as well as the phenomenon of virtual pitch. Early pitch perception models fall under two categories: <span style="font-weight: bold;">spectral models</span> and <span style="font-weight: bold;">temporal models</span>.</div><div>Spectral models of pitch perception, which are based on the frequency spectrum of sounds, tend to start with the Fourier analysis, which convert sound waves into its frequency components. One of the early spectral or <span style="font-weight: bold;">place models</span> was proposed by Helmholtz who speculated that each sinusoidal component of a sound triggers sensation at a place coding for pitch. In contrast, temporal models make use of the periodicity of waveforms comprising sounds. By calculating the time between periodic points in the waveform, the fundamental frequency can be calculated.</div><div>Modern theories of pitch perception take into account both spectral and temporal components of sound. Two types of modern pitch perception theories which receive the most support today are the pattern matching models and the autocorrelation models. Pattern-matching models of pitch perception, such as the <span style="font-weight: bold;">harmonic template matching model</span> (e.g. Lin &amp; Hartmann, 1998), postulate that we have stored in our brains a set of templates which, when frequency components are activated, we overlay onto the pattern of activation in order to calculate the fundamental pitch.</div><div>The autocorrelation models (Licklider, 1959) use a measure of <span style="font-style: italic;">self-similarity</span> of a waveform in order to derive its fundamental. It is based on the idea that a periodic waveform, when phase-shifted to exactly one period of its fundamental away from a starting point, should correlate perfectly with itself. By comparing the time lag between perfectly correlated frequency components, the model can derive the period of the complex sound, and thus the fundamental frequency.</div><div>The debate between pattern matching and autocorrelation models have received widely discussed among hearing researchers in recent years. While new data continues to emerge in support of either model, results from neuroscience looking for autocorrelators or harmonic templates in the auditory system may contribute to resolve these debates.</div><div><br/></div><div>ExistenceRegion</div><div>The <span style="font-weight: bold;">existence region</span> for pitch is the range in frequency at which melodies are transposable and can be perceived as a reasonable musical medium, e.g. can be used in melodies. Pressnitzer et al. (2001) define the existence region of melodic pitch as 30Hz to 3.2 kHz; however, the exact range of the practical existence region of melodic pitch is still under debate.</div><div><br/></div><div>Pressnitzer, D; Patterson, R; &amp; Krumbholtz. (2001). The lower limit of melodic pitch. JASA, 2076-2084.</div><div>PitchSpaces</div><div><br/></div><div>Throughout this unit we have discussed certain structural properties of pitch, including translational invariance and the importance of whole-number ratios. These structural properties have led various composers and music researchers to wonder about the structure of pitch material. Various attempts have been made to create visual representations of pitch structures. We will talk about a few of these representations, and how they are derived from perceptual experiments.</div><div>One method that has helped to derive pitch spaces is known as <span style="font-weight: bold;">multidimensional scaling</span>. Multidimensional scaling (MDS) is a quantitative method to map any series of items onto a perceptually meaningful space. In the typical multidimensional scaling experiment, the subject is given many pairs of items and asked to rate how similar they are to each other. These <span style="font-weight: bold;">dissimilarity judgments</span> are then fed into an MDS algorithm which defines a space that optimally represents all the judgments as distances such that items that are most similar are fitted closest together. These experiments have been performed on sets of pitches as well as on sets of chords. Krumhansl &amp; Shepard? Kessler? did MDS on chords, I think, and the solution mapped out best on the surface of a TORUS.</div><div>Shepard's model of pitch as a helix showed that pitch could be specified as two dimensions: pitch chroma versus pitch height. The vertical dimension of the helix represents <span style="font-weight: bold;">pitch height</span>, where different vertical positions map onto the same pitch class in different octaves. The circular dimension of the helix represents <span style="font-weight: bold;">pitch chroma</span>, where different circular positions along the same level of the helix map onto different pitch classes in the same octave. In this representation, a <span style="font-weight: bold;">Shepard tone</span> is a tone that is held stable in pitch height, but moving around in pitch chroma.</div><div>Click <a title="External link to http://cnmat.berkeley.edu/Music108/mp3s/asacd/52%20Circularity%20In%20Pitch%20Judgment.mp3" href="http://cnmat.berkeley.edu/Music108/mp3s/asacd/52%20Circularity%20In%20Pitch%20Judgment.mp3">here</a> for a demonstration of Shepard tones and Risset glides, both of which involve moving partials within a stable spectral envelope.</div><div><img src="MPC%20Day%207%3A%20Pitch.html.resources/D7642A93-0FA8-4908-9203-7D58BF2C8A79.png" height="436" width="277"/></div><div>(image source: <a title="External link to http://www.pdn.cam.ac.uk/groups/cnbh/research/publications/WUPG03/WUPG03.htm" href="http://www.pdn.cam.ac.uk/groups/cnbh/research/publications/WUPG03/WUPG03.htm">http://www.pdn.cam.ac.uk/groups/cnbh/research/publications/WUPG03/WUPG03.htm</a>) The helical representation of pitch chroma and height. Evidence that pitch chroma and pitch height activate different parts of the brain come from Warren et al (2003) who showed that changes in both chroma and height activate the auditory cortex, but changes in pitch chroma activate regions anterior to the regions activated by pitch height changes.</div><div>Another view of pitch and tonal material looks at harmony and key changes in addition to single pitches. Krumhansl, Kessler &amp; Bharucha (1983) found that dissimilarity judgments of pairs of chords map best onto a torus. The toroidal representation allows different tonal relations to map along the different planes of the torus, such that the C major key, for instance, is closely related to G major (circle of fifths), a minor (relative minor), and c minor (parallel minor).</div><div><img src="MPC%20Day%207%3A%20Pitch.html.resources/E6CCCA74-B54C-43A4-96A8-4C54769CEC91.png" height="353" width="523"/> (image source: Zatorre &amp; Krumhansl, 2003. <a title="External link to http://www.sciencemag.org/cgi/reprint/298/5601/2138.pdf" href="http://www.sciencemag.org/cgi/reprint/298/5601/2138.pdf">http://www.sciencemag.org/cgi/reprint/298/5601/2138.pdf</a>) The toroidal representation of tonal space, where keys that are more closely related to each other (e.g. adjacent along the circle of fifths, relative major or minor, and parallel major or minor) are located closer on the surface of the torus.</div><div>Janata et al (2003) found neural correlates of movement on the surface of the torus in the ventromedial prefrontal cortex. Stable voxels over many scanning sessions, but unstable as to which voxels correspond to which area in tonal space (key). It is as if the torus moves around in your head over different days.</div><div>Video showing continuously modulating melody activating the surface of the torus.</div><div>Also see <a title="External link to http://atonal.ucdavis.edu/%7Epetr/torus/movies/girl_from_ipanema_lbl.mov" href="http://atonal.ucdavis.edu/%7Epetr/torus/movies/girl_from_ipanema_lbl.mov">Girl from Ipanema video</a>.</div><div>Then there's also Lerdahl's cone-shaped pitich space. Lerdahl's book <span style="font-style: italic;">Tonal Pitch Space</span>.</div><div>Dmitri Tymoczko has developed a number of non-Euclidean geometrical structures for the representations of musical chords. His software, <a title="External link to http://www.music.princeton.edu/~dmitri/" href="http://www.music.princeton.edu/%7Edmitri/">Chord Geometries</a> is a demo of several geometrical lattice structures which allow for chords and chord inversions in different keys to be represented on the geometrical space.</div><div><img src="MPC%20Day%207%3A%20Pitch.html.resources/8F7E6A65-DDEB-475F-9C55-311DF1CAB993.jpg" height="383" width="436"/> (image source: <a title="External link to http://music.princeton.edu/%7Edmitri/ChordGeometries.html" href="http://music.princeton.edu/%7Edmitri/ChordGeometries.html">http://music.princeton.edu/%7Edmitri/ChordGeometries.html</a>) Tymoczko's 3D geometrical space. The corners represent areas of tonal stability, the brown nodes in the lattice structure represent chords, and the larger orange node represents the currently active chord. </div><div><br/></div></body></html>